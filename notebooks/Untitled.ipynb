{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "lol = np.random.random((3,96,96)) #, np.random.random(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = [3,4,5]\n",
    "lol[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol.pop()\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa4b8f3c950>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "disc = 0.98\n",
    "plt.plot(np.arange(30), disc**np.arange(30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "60//5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((1,5,1,5)).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 1, 5])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((1,5,1,5)).squeeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]],\n",
       "\n",
       "        [[1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi = torch.randn((25,5,1))\n",
    "torch.nn.functional.softmax(pi, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True, False,  True, False, False, False,  True,  True,\n",
       "       False, False,  True, False, False, False, False, False, False,\n",
       "       False, False,  True, False,  True, False,  True, False,  True,\n",
       "       False, False, False,  True, False, False,  True, False, False,\n",
       "        True,  True, False,  True, False, False, False, False, False,\n",
       "       False,  True,  True, False, False, False,  True, False, False,\n",
       "       False,  True, False, False,  True, False])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = []\n",
    "for i in range(3):\n",
    "    lol += [i]*20\n",
    "np.random.shuffle(lol)\n",
    "word = lol\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4768, -1.2795,  1.4634],\n",
       "        [ 1.4019,  0.1177, -2.9050],\n",
       "        [-0.9932,  0.4924, -2.8100],\n",
       "        [ 0.9400,  0.9240,  0.4721],\n",
       "        [ 2.4085, -0.0551, -1.3152],\n",
       "        [ 0.6035,  1.7827, -0.4705],\n",
       "        [ 0.0316, -0.9808,  0.6044],\n",
       "        [ 0.2355, -1.3085,  0.2938],\n",
       "        [-0.6921,  0.9296, -0.4586],\n",
       "        [ 0.6989,  0.2643, -0.3803],\n",
       "        [ 0.2538, -0.2881, -1.0081],\n",
       "        [-0.4519,  1.1247,  1.1590],\n",
       "        [-2.4658, -1.3038, -0.7662],\n",
       "        [-0.7875,  1.4587,  1.5525],\n",
       "        [-0.5312,  1.0609,  1.5424],\n",
       "        [ 0.6742, -0.2059,  2.0007],\n",
       "        [ 1.2401, -1.0702,  0.7041],\n",
       "        [ 0.7861, -1.3296,  1.1712],\n",
       "        [-0.1146,  1.1345, -0.3478],\n",
       "        [-0.9163, -1.2437,  0.9269]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn((60,3))[np.asarray(word)==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lol.shape[1:])*[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(('hey', 'yo', 'yess'), 'teehee')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def func2():\n",
    "    return 'hey', 'yo', 'yess'\n",
    "def func1():\n",
    "    return func2(), 'teehee'\n",
    "\n",
    "func1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.distributions.Uniform(-1,1).sample((32, 3));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-b910f9aff006>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/distributions/normal.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/distributions/distribution.py\u001b[0m in \u001b[0;36m_extended_shape\u001b[0;34m(self, sample_shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \"\"\"\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0msample_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msample_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_shape\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not iterable"
     ]
    }
   ],
   "source": [
    "lol = torch.distributions.Normal(torch.Tensor([1,2,3]),torch.Tensor([1,2,3] )) \n",
    "lol.sample(5).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([[3,4,5],[1,2,3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6076,  0.5123,  0.3088],\n",
       "        [-0.1528, -0.5379, -0.1104],\n",
       "        [-0.3247,  0.3300, -0.0676],\n",
       "        [ 0.2272, -0.5675,  0.0752],\n",
       "        [ 0.6708, -0.5474, -0.1936],\n",
       "        [-0.7362, -0.7160,  0.5744],\n",
       "        [ 0.0857, -0.5703,  0.7098],\n",
       "        [ 0.4690,  0.3631, -0.4669],\n",
       "        [-0.5091, -0.6209,  0.7187],\n",
       "        [-0.6992, -0.3501, -0.5870],\n",
       "        [-0.7349,  0.5002, -0.2789],\n",
       "        [-0.3928, -0.3933, -0.6665],\n",
       "        [ 0.4754,  0.4929,  0.6526],\n",
       "        [ 0.7195, -0.5097, -0.6166],\n",
       "        [ 0.3596,  0.4000,  0.2933],\n",
       "        [ 0.7017,  0.3844, -0.4769],\n",
       "        [ 0.5837, -0.2403, -0.7217],\n",
       "        [-0.0569,  0.4905, -0.1546],\n",
       "        [ 0.5147, -0.7210, -0.6160],\n",
       "        [ 0.4395, -0.3802,  0.6433]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = torch.distributions.Uniform(-1,1).sample((20, 3))\n",
    "out = torch.tanh(out)\n",
    "out[0,1] = (out[0,1]+1)/2.0 # this converts tanh to sigmoid\n",
    "out[0,2] = torch.clamp(out[0,2], min=0.0, max=1.0)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.0000,  0.5123,  0.3088],\n",
       "        [-0.1528, -0.5379, -0.1104],\n",
       "        [-0.3247,  0.3300, -0.0676],\n",
       "        [ 0.2272, -0.5675,  0.0752],\n",
       "        [ 0.6708, -0.5474, -0.1936],\n",
       "        [-0.7362, -0.7160,  0.5744],\n",
       "        [ 0.0857, -0.5703,  0.7098],\n",
       "        [ 0.4690,  0.3631, -0.4669],\n",
       "        [-0.5091, -0.6209,  0.7187],\n",
       "        [-0.6992, -0.3501, -0.5870],\n",
       "        [-0.7349,  0.5002, -0.2789],\n",
       "        [-0.3928, -0.3933, -0.6665],\n",
       "        [ 0.4754,  0.4929,  0.6526],\n",
       "        [ 0.7195, -0.5097, -0.6166],\n",
       "        [ 0.3596,  0.4000,  0.2933],\n",
       "        [ 0.7017,  0.3844, -0.4769],\n",
       "        [ 0.5837, -0.2403, -0.7217],\n",
       "        [-0.0569,  0.4905, -0.1546],\n",
       "        [ 0.5147, -0.7210, -0.6160],\n",
       "        [ 0.4395, -0.3802,  0.6433]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0,0] = 5\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 5, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = torch.randn((1,5,3))\n",
    "lol.repeat(5,*len(lol.shape[1:])*[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Track generation: 1071..1343 -> 272-tiles track\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can only concatenate str (not \"bytes\") to str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyglet/libs/darwin/cocoapy/runtime.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, objc_id, *args)\u001b[0m\n\u001b[1;32m    754\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobjc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m             \u001b[0;31m# Convert result to python type if it is a instance or class pointer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument 1: <class 'RecursionError'>: maximum recursion depth exceeded while calling a Python object",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m_ctypes/callbacks.c\u001b[0m in \u001b[0;36m'calling callback function'\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyglet/libs/darwin/cocoapy/runtime.py\u001b[0m in \u001b[0;36mobjc_method\u001b[0;34m(objc_self, objc_cmd, *args)\u001b[0m\n\u001b[1;32m   1119\u001b[0m                 \u001b[0mpy_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjc_cmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobjc_cmd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_method_arguments\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpy_self\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mObjCClass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyglet/window/cocoa/pyglet_window.py\u001b[0m in \u001b[0;36mnextEventMatchingMask_untilDate_inMode_dequeue_\u001b[0;34m(self, mask, date, mode, dequeue)\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mPygletWindow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'@'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mNSUIntegerEncoding\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34mb'@@B'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnextEventMatchingMask_untilDate_inMode_dequeue_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdequeue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minLiveResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m             \u001b[0;31m# Call the idle() method while we're stuck in a live resize event.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mpyglet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyglet/libs/darwin/cocoapy/runtime.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    783\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m         \u001b[0;34m\"\"\"Call the method with the given arguments.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjc_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;31m######################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pyglet/libs/darwin/cocoapy/runtime.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, objc_id, *args)\u001b[0m\n\u001b[1;32m    762\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m             \u001b[0;31m# Add more useful info to argument error exceptions, then reraise.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m             error.args += ('selector = ' + self.name,\n\u001b[0m\u001b[1;32m    765\u001b[0m                            \u001b[0;34m'argtypes ='\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margtypes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m                            'encoding = ' + self.encoding)\n",
      "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"bytes\") to str"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# serial version\n",
    "def run1():\n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    env.reset()\n",
    "    steps = []\n",
    "    for _ in range(1000):\n",
    "        steps += [env.step(env.action_space.sample())]\n",
    "    return len(steps)\n",
    "\n",
    "%time result = [run1() for i in range(100)]\n",
    "print(sum(result))\n",
    "\n",
    "@ray.remote\n",
    "def run2():  # same as run1 \n",
    "    env = gym.make(\"CartPole-v0\")\n",
    "    env.reset()\n",
    "    steps = []\n",
    "    for _ in range(1000):\n",
    "        steps += [env.step(env.action_space.sample())]\n",
    "    return len(steps)\n",
    "\n",
    "# note: maybe run this twice to warmup the system\n",
    "%time result = ray.get([run2.remote() for i in range(100)])\n",
    "print(sum(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lolz': [5], 'tree': [6]}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urgh = dict(lolz=5, tree=6)\n",
    "d = {k:[v] for k, v in urgh.items()}\n",
    "d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 5]\n",
      "[6, 6, 6]\n"
     ]
    }
   ],
   "source": [
    "for k, v in d.items():\n",
    "    print(v)\n",
    "    v.append(urgh[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{k:v.append(urgh[k]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "which g torch.Size([10, 32]) torch.Size([10, 5, 32])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "md_logpi = torch.randn((1, 10,5,32))\n",
    "md_mus = torch.randn((1,10,5,32))\n",
    "md_sigmas = torch.randn((1,10,5,32))\n",
    "\n",
    "g_probs = torch.distributions.Categorical(probs=torch.exp(md_logpi.squeeze()).permute(0,2,1))\n",
    "which_g = g_probs.sample()\n",
    "print('which g', which_g.shape, md_mus.squeeze().shape)\n",
    "mus_g, sigs_g = torch.gather(md_mus.squeeze(), 1, which_g.unsqueeze(1)), torch.gather(md_sigmas.squeeze(), 1, which_g.unsqueeze(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 32, 5])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_logpi.squeeze().permute(0,2,1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4226, -0.1532,  0.1831],\n",
       "         [-1.7333,  0.6322, -1.3454],\n",
       "         [-0.5202,  0.5227, -0.0040],\n",
       "         [ 0.2073,  0.0124,  0.4767],\n",
       "         [ 1.4064, -0.1722, -0.2135]],\n",
       "\n",
       "        [[ 0.5565,  0.6343,  0.8731],\n",
       "         [ 0.4362, -0.2045,  1.2388],\n",
       "         [-0.9787,  0.7820,  0.6471],\n",
       "         [-0.7562, -0.7615,  0.8965],\n",
       "         [-1.5286,  1.0121,  2.5571]],\n",
       "\n",
       "        [[-0.8431, -1.1016, -0.0166],\n",
       "         [-0.6350, -0.4335,  1.8687],\n",
       "         [-1.8204,  0.4773,  0.2947],\n",
       "         [ 0.1919,  3.5515,  0.1440],\n",
       "         [-0.1534, -0.4970, -0.5794]],\n",
       "\n",
       "        [[-0.2413, -0.3020,  0.8422],\n",
       "         [ 0.6990, -1.9366,  0.8286],\n",
       "         [-0.9251,  0.0673,  0.4389],\n",
       "         [-0.3918,  0.5636,  0.3824],\n",
       "         [ 0.1956, -1.2146, -1.1355]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol = torch.randn((4,5,3))\n",
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 4],\n",
       "        [2, 0, 0],\n",
       "        [3, 1, 0],\n",
       "        [2, 3, 3]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_probs = torch.distributions.Categorical(logits=torch.randn((4,5,3)).permute(0,2,1))\n",
    "which_g = g_probs.sample()\n",
    "which_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_g.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 5, 3])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4226, -0.1532,  0.1831],\n",
       "         [-1.7333,  0.6322, -1.3454],\n",
       "         [-0.5202,  0.5227, -0.0040],\n",
       "         [ 0.2073,  0.0124,  0.4767],\n",
       "         [ 1.4064, -0.1722, -0.2135]],\n",
       "\n",
       "        [[ 0.5565,  0.6343,  0.8731],\n",
       "         [ 0.4362, -0.2045,  1.2388],\n",
       "         [-0.9787,  0.7820,  0.6471],\n",
       "         [-0.7562, -0.7615,  0.8965],\n",
       "         [-1.5286,  1.0121,  2.5571]],\n",
       "\n",
       "        [[-0.8431, -1.1016, -0.0166],\n",
       "         [-0.6350, -0.4335,  1.8687],\n",
       "         [-1.8204,  0.4773,  0.2947],\n",
       "         [ 0.1919,  3.5515,  0.1440],\n",
       "         [-0.1534, -0.4970, -0.5794]],\n",
       "\n",
       "        [[-0.2413, -0.3020,  0.8422],\n",
       "         [ 0.6990, -1.9366,  0.8286],\n",
       "         [-0.9251,  0.0673,  0.4389],\n",
       "         [-0.3918,  0.5636,  0.3824],\n",
       "         [ 0.1956, -1.2146, -1.1355]]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(lol, 1, which_g.unsqueeze(1)).squeeze().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.4226, -0.1532,  0.1831],\n",
       "         [-1.7333,  0.6322, -1.3454],\n",
       "         [-0.5202,  0.5227, -0.0040],\n",
       "         [ 0.2073,  0.0124,  0.4767],\n",
       "         [ 1.4064, -0.1722, -0.2135]],\n",
       "\n",
       "        [[ 0.5565,  0.6343,  0.8731],\n",
       "         [ 0.4362, -0.2045,  1.2388],\n",
       "         [-0.9787,  0.7820,  0.6471],\n",
       "         [-0.7562, -0.7615,  0.8965],\n",
       "         [-1.5286,  1.0121,  2.5571]]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 5, 3])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lol[0:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 and 3 did it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2, 3, 2],\n",
       "        [0, 4, 0]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_g[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "which_g[0:2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.5202,  0.0124, -0.0040]],\n",
       "\n",
       "        [[ 0.5565,  1.0121,  0.8731]]])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(lol[0:2], 1, which_g[0:2].unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not [1,2,4]: \n",
    "    print('hey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_workers = 16\n",
    "import numpy as np\n",
    "num_workers- np.floor(num_workers*0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.flatten(torch.randn((3,3,9)),end_dim=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59519127])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.random(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.9931)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.distributions.Normal(0.4, 0.02).log_prob(0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToPILImage(),\n",
    "                transforms.Resize((64, 64)),\n",
    "                transforms.ToTensor()\n",
    "            ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input type float64 is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-09e8f590bb66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \"\"\"\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pil_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_pil_image\u001b[0;34m(pic, mode)\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Input type {} is not supported'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfromarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnpimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input type float64 is not supported"
     ]
    }
   ],
   "source": [
    "transform(lol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
